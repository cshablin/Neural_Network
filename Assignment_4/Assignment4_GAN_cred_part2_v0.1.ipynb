{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4_GAN_cred_part2_v0.1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kmcxRzCD1nh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import arff\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, backend \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Input, concatenate, BatchNormalization, LeakyReLU, Flatten\n",
        "import joblib\n",
        "\n",
        "import time\n",
        "from typing import Tuple, List\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cicvn2rxESII",
        "outputId": "2ef6c6d5-97ea-482c-b215-08bb9f643bb4"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jKiT0ibayGO"
      },
      "source": [
        "def split_df_to_train_val(df, ratio):\n",
        "    mask = np.random.rand(len(df)) < ratio\n",
        "    df_train = df[mask]\n",
        "    df_val = df[~mask]\n",
        "    return df_train, df_val"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOGIpDPoElpj"
      },
      "source": [
        "def load_data() -> pd.DataFrame:\n",
        "    diab_arf = arff.loadarff('gdrive/MyDrive/DL/Assignment_4/german_credit.arff')\n",
        "    diab_df = pd.DataFrame(diab_arf[0])\n",
        "    return diab_df\n",
        "    \n",
        "def prepare():\n",
        "    cred_df = load_data()\n",
        "    # y = cred_df.pop('21')\n",
        "    # print(cred_df.describe())\n",
        "    cat_labels = ['1', '3', '4', '6', '7', '9', '10', '12', '14', '15', '17', '19', '20']\n",
        "    # One hot encoding\n",
        "    df = pd.get_dummies(cred_df, columns=cat_labels)\n",
        "    df = df.astype('float')\n",
        "    # numeric scaling\n",
        "    scale = MinMaxScaler(feature_range=(-1, 1))\n",
        "    scaled_values = scale.fit_transform(df)\n",
        "    df.loc[:, :] = scaled_values\n",
        "\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "vug2wKS6aK2r",
        "outputId": "da3c4064-c1ab-404c-8b55-dad6bec9be86"
      },
      "source": [
        "df_credit = prepare()\n",
        "df_credit.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>5</th>\n",
              "      <th>8</th>\n",
              "      <th>11</th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>21</th>\n",
              "      <th>1_b'A11'</th>\n",
              "      <th>1_b'A12'</th>\n",
              "      <th>1_b'A13'</th>\n",
              "      <th>1_b'A14'</th>\n",
              "      <th>3_b'A30'</th>\n",
              "      <th>3_b'A31'</th>\n",
              "      <th>3_b'A32'</th>\n",
              "      <th>3_b'A33'</th>\n",
              "      <th>3_b'A34'</th>\n",
              "      <th>4_b'A40'</th>\n",
              "      <th>4_b'A41'</th>\n",
              "      <th>4_b'A410'</th>\n",
              "      <th>4_b'A42'</th>\n",
              "      <th>4_b'A43'</th>\n",
              "      <th>4_b'A44'</th>\n",
              "      <th>4_b'A45'</th>\n",
              "      <th>4_b'A46'</th>\n",
              "      <th>4_b'A48'</th>\n",
              "      <th>4_b'A49'</th>\n",
              "      <th>6_b'A61'</th>\n",
              "      <th>6_b'A62'</th>\n",
              "      <th>6_b'A63'</th>\n",
              "      <th>6_b'A64'</th>\n",
              "      <th>6_b'A65'</th>\n",
              "      <th>7_b'A71'</th>\n",
              "      <th>7_b'A72'</th>\n",
              "      <th>7_b'A73'</th>\n",
              "      <th>7_b'A74'</th>\n",
              "      <th>7_b'A75'</th>\n",
              "      <th>9_b'A91'</th>\n",
              "      <th>9_b'A92'</th>\n",
              "      <th>9_b'A93'</th>\n",
              "      <th>9_b'A94'</th>\n",
              "      <th>10_b'A101'</th>\n",
              "      <th>10_b'A102'</th>\n",
              "      <th>10_b'A103'</th>\n",
              "      <th>12_b'A121'</th>\n",
              "      <th>12_b'A122'</th>\n",
              "      <th>12_b'A123'</th>\n",
              "      <th>12_b'A124'</th>\n",
              "      <th>14_b'A141'</th>\n",
              "      <th>14_b'A142'</th>\n",
              "      <th>14_b'A143'</th>\n",
              "      <th>15_b'A151'</th>\n",
              "      <th>15_b'A152'</th>\n",
              "      <th>15_b'A153'</th>\n",
              "      <th>17_b'A171'</th>\n",
              "      <th>17_b'A172'</th>\n",
              "      <th>17_b'A173'</th>\n",
              "      <th>17_b'A174'</th>\n",
              "      <th>19_b'A191'</th>\n",
              "      <th>19_b'A192'</th>\n",
              "      <th>20_b'A201'</th>\n",
              "      <th>20_b'A202'</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.941176</td>\n",
              "      <td>-0.898867</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>-0.372620</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.892857</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.764706</td>\n",
              "      <td>-0.796853</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.117647</td>\n",
              "      <td>-0.160119</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.491581</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          2         5         8  ...  19_b'A192'  20_b'A201'  20_b'A202'\n",
              "0 -0.941176 -0.898867  1.000000  ...         1.0         1.0        -1.0\n",
              "1  0.294118 -0.372620 -0.333333  ...        -1.0         1.0        -1.0\n",
              "2 -0.764706 -0.796853 -0.333333  ...        -1.0         1.0        -1.0\n",
              "3  0.117647 -0.160119 -0.333333  ...        -1.0         1.0        -1.0\n",
              "4 -0.411765 -0.491581  0.333333  ...        -1.0         1.0        -1.0\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "-Du89EeNWrKZ",
        "outputId": "14ec880b-33d2-4fdf-a35c-6779c9fded09"
      },
      "source": [
        "df_train, df_test = split_df_to_train_val(df_credit, 0.7)\n",
        "y_train = df_train.pop('21')\n",
        "y_test = df_test.pop('21')\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>5</th>\n",
              "      <th>8</th>\n",
              "      <th>11</th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>1_b'A11'</th>\n",
              "      <th>1_b'A12'</th>\n",
              "      <th>1_b'A13'</th>\n",
              "      <th>1_b'A14'</th>\n",
              "      <th>3_b'A30'</th>\n",
              "      <th>3_b'A31'</th>\n",
              "      <th>3_b'A32'</th>\n",
              "      <th>3_b'A33'</th>\n",
              "      <th>3_b'A34'</th>\n",
              "      <th>4_b'A40'</th>\n",
              "      <th>4_b'A41'</th>\n",
              "      <th>4_b'A410'</th>\n",
              "      <th>4_b'A42'</th>\n",
              "      <th>4_b'A43'</th>\n",
              "      <th>4_b'A44'</th>\n",
              "      <th>4_b'A45'</th>\n",
              "      <th>4_b'A46'</th>\n",
              "      <th>4_b'A48'</th>\n",
              "      <th>4_b'A49'</th>\n",
              "      <th>6_b'A61'</th>\n",
              "      <th>6_b'A62'</th>\n",
              "      <th>6_b'A63'</th>\n",
              "      <th>6_b'A64'</th>\n",
              "      <th>6_b'A65'</th>\n",
              "      <th>7_b'A71'</th>\n",
              "      <th>7_b'A72'</th>\n",
              "      <th>7_b'A73'</th>\n",
              "      <th>7_b'A74'</th>\n",
              "      <th>7_b'A75'</th>\n",
              "      <th>9_b'A91'</th>\n",
              "      <th>9_b'A92'</th>\n",
              "      <th>9_b'A93'</th>\n",
              "      <th>9_b'A94'</th>\n",
              "      <th>10_b'A101'</th>\n",
              "      <th>10_b'A102'</th>\n",
              "      <th>10_b'A103'</th>\n",
              "      <th>12_b'A121'</th>\n",
              "      <th>12_b'A122'</th>\n",
              "      <th>12_b'A123'</th>\n",
              "      <th>12_b'A124'</th>\n",
              "      <th>14_b'A141'</th>\n",
              "      <th>14_b'A142'</th>\n",
              "      <th>14_b'A143'</th>\n",
              "      <th>15_b'A151'</th>\n",
              "      <th>15_b'A152'</th>\n",
              "      <th>15_b'A153'</th>\n",
              "      <th>17_b'A171'</th>\n",
              "      <th>17_b'A172'</th>\n",
              "      <th>17_b'A173'</th>\n",
              "      <th>17_b'A174'</th>\n",
              "      <th>19_b'A191'</th>\n",
              "      <th>19_b'A192'</th>\n",
              "      <th>20_b'A201'</th>\n",
              "      <th>20_b'A202'</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.294118</td>\n",
              "      <td>-0.372620</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.892857</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.764706</td>\n",
              "      <td>-0.796853</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.117647</td>\n",
              "      <td>-0.160119</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.071429</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.715528</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.058824</td>\n",
              "      <td>-0.262903</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.428571</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          2         5         8  ...  19_b'A192'  20_b'A201'  20_b'A202'\n",
              "1  0.294118 -0.372620 -0.333333  ...        -1.0         1.0        -1.0\n",
              "2 -0.764706 -0.796853 -0.333333  ...        -1.0         1.0        -1.0\n",
              "3  0.117647 -0.160119 -0.333333  ...        -1.0         1.0        -1.0\n",
              "6 -0.411765 -0.715528  0.333333  ...        -1.0         1.0        -1.0\n",
              "7 -0.058824 -0.262903 -0.333333  ...         1.0         1.0        -1.0\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0dv1dvMkesv",
        "outputId": "afa20eaf-af7f-426b-b69c-40b8830f8ece"
      },
      "source": [
        "# rf.fit(df_train, y_train)\n",
        "# rf.oob_score_\n",
        "\n",
        "# using cross-validation and grid-search\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "parameters = {\n",
        "    'max_features': ('auto', 'sqrt', 10, 12, 20, 30),\n",
        "    'max_depth': (5, 10, 15, None),\n",
        "    'n_estimators': (100, 200, 500, 1000, 2000)\n",
        "}\n",
        "gs_rf = GridSearchCV(estimator=rf, param_grid=parameters, cv=5, n_jobs=-1, verbose=3)\n",
        "gs_rf.fit(df_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 13.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'max_depth': (5, 10, 15, None),\n",
              "                         'max_features': ('auto', 'sqrt', 10, 12, 20, 30),\n",
              "                         'n_estimators': (100, 200, 500, 1000, 2000)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDk6y8VAMQmk",
        "outputId": "3cb85682-bc7e-46f1-d4bd-c11e4dc4250f"
      },
      "source": [
        "gs_rf.best_params_"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS3GNQNLTgxw",
        "outputId": "a9df48a4-e1e8-474a-ff56-4e9b26adc080"
      },
      "source": [
        "gs_rf.best_score_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7652482269503545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9olZc8EmlH_",
        "outputId": "480d519c-eda3-4926-a248-a479a8c6d4e5"
      },
      "source": [
        "p = gs_rf.predict(df_test)\n",
        "confusion_matrix(y_test.values, p)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[197,  13],\n",
              "       [ 56,  27]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB33XCTwnp2y",
        "outputId": "1e69147d-63a0-4347-b4db-7c894a95d16f"
      },
      "source": [
        "print(classification_report(y_test.values, p,labels=[1,-1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.33      0.44        83\n",
            "          -1       0.78      0.94      0.85       210\n",
            "\n",
            "    accuracy                           0.76       293\n",
            "   macro avg       0.73      0.63      0.64       293\n",
            "weighted avg       0.75      0.76      0.73       293\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm5gwJr9pmA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f3bb2f-087b-40a9-967b-5fbf29fb51f5"
      },
      "source": [
        "joblib.dump(gs_rf, \"/content/gdrive/MyDrive/DL/Assignment_4/random_forest_cred.joblib\")\n",
        "# gs_rf = joblib.load(\"/content/gdrive/MyDrive/DL/Assignment_4/random_forest_cred.joblib\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/DL/Assignment_4/random_forest_cred.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9oEzK68SvBO"
      },
      "source": [
        "class GAN:\n",
        "    def __init__(self, latent_dim, gen_out_size, gen_final_activation='tanh'):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.generator_vector_size = gen_out_size\n",
        "        self.discriminator_input_shape = (self.generator_vector_size,)\n",
        "\n",
        "        self.generator = self.make_generator_model(gen_final_activation)\n",
        "        self.discriminator = self.make_discriminator_model()\n",
        "        self.gan = self.combime_gan(self.generator, self.discriminator)\n",
        "\n",
        "    def combime_gan(self, g_model, d_model):\n",
        "        # make weights in the discriminator not trainable\n",
        "        d_model.trainable = False\n",
        "\n",
        "        g_input = Input(shape=(self.latent_dim,))\n",
        "        c_input = Input(shape=(1,))\n",
        "\n",
        "        \n",
        "        g_sample = g_model([g_input, c_input])\n",
        "\n",
        "        # c_input = Input(shape=(1,))\n",
        "        # c_input = Input(shape=(1,))\n",
        "        # print(g_sample)\n",
        "        # print(g_sample.shape)\n",
        "        # proto_tensor = tf.make_tensor_proto(g_sample)  # convert `tensor a` to a proto tensor\n",
        "        \n",
        "        # y =  gs_rf.predict_proba(tf.make_ndarray(proto_tensor))[:,0]  # evaluate Y by running RF classifier\n",
        "        # # shuffle c and y\n",
        "        # # idx = np.random.randint(0, c.shape, n_samples)\n",
        "        # # for i, ix in enumerate(range(idx)):\n",
        "        # #   if ix == 1:\n",
        "        # #     tmp = c[i]\n",
        "        # #     c[i] = y[i]\n",
        "        # #     y[i] = tmp\n",
        "\n",
        "        d_desision = d_model([g_sample, c_input, c_input])\n",
        "\n",
        "        gan_model = Model([g_input, c_input], d_desision)\n",
        "        # opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "        opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.6,beta_2=0.999 )\n",
        "        gan_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        # connect generator and discriminator\n",
        "        # model = tf.keras.Sequential()\n",
        "        # model.add(g_model)\n",
        "        # model.add(d_model)\n",
        "        # opt = tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
        "        # model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        return gan_model\n",
        "\n",
        "    def make_generator_model(self, gen_final_activation):\n",
        "        input_noise = Input(shape=(self.latent_dim,))\n",
        "        c_input = Input(shape=(1,))\n",
        "        concat_layer_c = concatenate([input_noise, c_input]) \n",
        "        dense_1 = Dense(128, use_bias=True)(concat_layer_c)\n",
        "        dense_1_bn = BatchNormalization()(dense_1)\n",
        "        dense_1_lr = LeakyReLU()(dense_1_bn)\n",
        "        dense_1_do = Dropout(0.25)(dense_1_lr)\n",
        "        dense_2 = Dense(256)(dense_1_do)\n",
        "        dense_2_bn = BatchNormalization()(dense_2)\n",
        "        dense_2_lr = LeakyReLU()(dense_2_bn)\n",
        "        dense_2_do = Dropout(0.25)(dense_2_lr)\n",
        "        dense_3 = Dense(512)(dense_2_do)\n",
        "        dense_3_bn = BatchNormalization()(dense_3)\n",
        "        dense_3_lr = LeakyReLU()(dense_3_bn)\n",
        "        dense_3_do = Dropout(0.25)(dense_3_lr)\n",
        "        final_layer = Dense(self.generator_vector_size, activation=gen_final_activation)(dense_3_do)\n",
        "        # concat_layer = concatenate([final_layer, c_input])\n",
        "        model = Model(inputs=[input_noise, c_input], outputs=final_layer)\n",
        "\n",
        "        # final_model_1 = concatenate([lyrics_model, bn2])\n",
        "        # final_model = Dense(units=vocab_size, activation='softmax')(final_model_1)\n",
        "        # self.model = Model(inputs=[input_lyrics, input_midi], outputs=final_model)\n",
        "        # self.model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        # self.model.summary()\n",
        "\n",
        "\n",
        "        # model = tf.keras.Sequential()\n",
        "        # model.add(layers.Dense(30, use_bias=True, input_dim=self.latent_dim))\n",
        "        # model.add(layers.BatchNormalization())\n",
        "        # model.add(layers.LeakyReLU())\n",
        "\n",
        "        # model.add(layers.Dense(15))\n",
        "        # model.add(layers.BatchNormalization())\n",
        "        # model.add(layers.LeakyReLU())\n",
        "        # model.add(layers.Dense(self.generator_vector_size, activation='tanh'))\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "        # noise = tf.keras.layers.Input(shape=(self.latent_dim,))\n",
        "        # g_rows = model(noise)\n",
        "        # return tf.keras.Model(noise, g_rows)\n",
        "        # return model\n",
        "\n",
        "    def make_discriminator_model(self):\n",
        "\n",
        "        input_sample = Input(shape=self.discriminator_input_shape,)\n",
        "        cy1_input = Input(shape=(1,))\n",
        "        cy2_input = Input(shape=(1,))\n",
        "        \n",
        "        # --------- arc1\n",
        "        # dense_1 = Dense(32, use_bias=True)(input_sample)\n",
        "        # dense_1_lr = LeakyReLU()(dense_1)\n",
        "        # dense_1_do = Dropout(0.2)(dense_1_lr)\n",
        "        # dense_2 = Dense(16)(dense_1_do)\n",
        "        # dense_2_lr = LeakyReLU()(dense_2)\n",
        "        # dense_2_do = Dropout(0.2)(dense_2_lr)\n",
        "        # flatten = Flatten()(dense_2_do)\n",
        "        # concat_layer_c = concatenate([dense_2_do, cy1_input]) \n",
        "        # cy1_score = Dense(1, activation='sigmoid')(concat_layer_c)\n",
        "        # concat_layer_y = concatenate([dense_2_do, cy2_input]) \n",
        "        # cy2_score = Dense(1, activation='sigmoid')(concat_layer_y)\n",
        "        # concat_layer_final = concatenate([cy1_score, cy2_score]) \n",
        "        # final_layer = Dense(1, activation='sigmoid')(concat_layer_final)\n",
        "        # # concat_layer = concatenate([dense_2_do, c_input, y_input])        \n",
        "        # model = Model(inputs=[input_sample, cy1_input, cy2_input], outputs=final_layer)\n",
        "\n",
        "        # --------- arc2\n",
        "        # dense_1 = Dense(32, use_bias=True)(input_sample)\n",
        "        # dense_1_lr = LeakyReLU()(dense_1)\n",
        "        # dense_1_do = Dropout(0.2)(dense_1_lr)\n",
        "        # dense_2 = Dense(16)(dense_1_do)\n",
        "        # dense_2_lr = LeakyReLU()(dense_2)\n",
        "        # dense_2_do = Dropout(0.2)(dense_2_lr)\n",
        "        # flatten = Flatten()(dense_2_do)\n",
        "        # concat_layer_c = concatenate([dense_2_do, cy1_input, cy2_input]) \n",
        "        # final_layer = Dense(1, activation='sigmoid')(concat_layer_c)\n",
        "        # # concat_layer = concatenate([dense_2_do, c_input, y_input])        \n",
        "        # model = Model(inputs=[input_sample, cy1_input, cy2_input], outputs=final_layer)\n",
        "\n",
        "\n",
        "        # --------- arc3\n",
        "        concat_layer_c = concatenate([input_sample, cy1_input, cy2_input])\n",
        "        dense_1 = Dense(512, use_bias=True)(input_sample)\n",
        "        dense_1_lr = LeakyReLU()(dense_1)\n",
        "        dense_1_do = Dropout(0.2)(dense_1_lr)\n",
        "        dense_2 = Dense(256)(dense_1_do)\n",
        "        dense_2_lr = LeakyReLU()(dense_2)\n",
        "        dense_2_do = Dropout(0.2)(dense_2_lr)\n",
        "        dense_3 = Dense(128)(dense_2_do)\n",
        "        dense_3_lr = LeakyReLU()(dense_3)\n",
        "        dense_3_do = Dropout(0.2)(dense_3_lr)\n",
        "        flatten = Flatten()(dense_3_do)\n",
        "        # layer_final_sm = Dense(2, activation='softmax')(flatten)\n",
        "        final_layer = Dense(1, activation='sigmoid')(flatten)\n",
        "        # concat_layer = concatenate([dense_2_do, c_input, y_input])        \n",
        "        model = Model(inputs=[input_sample, cy1_input, cy2_input], outputs=final_layer)\n",
        "\n",
        "        # --------- arc4\n",
        "        # dense_1 = Dense(32, use_bias=True)(input_sample)\n",
        "        # dense_1_lr = LeakyReLU()(dense_1)\n",
        "        # dense_1_do = Dropout(0.2)(dense_1_lr)\n",
        "        # dense_2 = Dense(16)(dense_1_do)\n",
        "        # dense_2_lr = LeakyReLU()(dense_2)\n",
        "        # dense_2_do = Dropout(0.2)(dense_2_lr)\n",
        "        # flatten = Flatten()(dense_2_do)\n",
        "        # concat_layer_c = concatenate([dense_2_do, cy1_input]) \n",
        "        # cy1_score = Dense(1, activation='sigmoid')(concat_layer_c)\n",
        "        # concat_layer_y = concatenate([dense_2_do, cy2_input]) \n",
        "        # cy2_score = Dense(1, activation='sigmoid')(concat_layer_y)\n",
        "        # concat_layer_final = concatenate([cy1_score, cy2_score]) \n",
        "        # concat_layer_final_sm = Dense(2, activation='softmax')(concat_layer_final)\n",
        "        # final_layer = Dense(1, activation='sigmoid')(concat_layer_final)\n",
        "        # # concat_layer = concatenate([dense_2_do, c_input, y_input])        \n",
        "        # model = Model(inputs=[input_sample, cy1_input, cy2_input], outputs=final_layer)\n",
        "\n",
        "\n",
        "\n",
        "        # dense_2 = Dense(self.generator_vector_size, activation='tanh')(dense_2_lr)\n",
        "        # final_layer = tanh()(dense_2)\n",
        "        # model = Model(inputs=[input_noise, c_input], outputs=final_layer)      \n",
        "\n",
        "        # model = tf.keras.Sequential()\n",
        "        # model.add(layers.Dense(32, use_bias=True, input_shape=self.discriminator_input_shape))\n",
        "        # # model.add(layers.Dense(32, use_bias=False, input_shape=(8,)))\n",
        "        # model.add(layers.LeakyReLU())\n",
        "        # model.add(layers.Dropout(0.2))\n",
        "\n",
        "        # model.add(layers.Dense(16))\n",
        "        # model.add(layers.LeakyReLU())\n",
        "        # model.add(layers.Dropout(0.2))\n",
        "\n",
        "        # model.add(layers.Flatten())\n",
        "        # model.add(layers.Dense(1, activation='sigmoid'))\n",
        "        # opt = tf.keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
        "        opt = tf.keras.optimizers.Adam(lr=0.000015, beta_1=0.95)  # lr=0.0002, beta_1=0.5, beta_2=0.999\n",
        "        model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "        # g_rows = tf.keras.layers.Input(shape=self.discriminator_input_shape)\n",
        "        # validity = model(g_rows)\n",
        "        # return tf.keras.Model(g_rows, validity)\n",
        "\n",
        "\n",
        "    # def generate_real_x_y(self, data: np.ndarray, n_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    #     y_real = np.ones((n_samples, 1))\n",
        "    #     idx = np.random.randint(0, data.shape[0], n_samples)\n",
        "    #     x_real = data[idx]\n",
        "    #     return x_real, y_real\n",
        "\n",
        "    # def generate_fake_x_y(self, n_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    #     y_fake = np.zeros((n_samples, 1))\n",
        "    #     noise = np.random.normal(0, 1, (n_samples, self.latent_dim))\n",
        "    #     x_fake = self.generator.predict(noise)\n",
        "    #     return x_fake, y_fake\n",
        "\n",
        "    def train(self, epochs, batch_size=8):\n",
        "        # (X_train, _), (_, _) = mnist.load_data()\n",
        "        # X_train = X_train / 127.5 - 1.\n",
        "        # X_train = np.expand_dims(X_train, axis=3)\n",
        "        # X_train = df.values\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        invalid = np.zeros((batch_size, 1))\n",
        "        valid_twice = np.ones((batch_size * 2, 1))\n",
        "        # fake = np.zeros((batch_size, 1))\n",
        "        d_losses = np.zeros((epochs, 1))\n",
        "        d_accuracies = np.zeros((epochs, 1))\n",
        "        # d_fake_losses = np.zeros((epochs, 1))\n",
        "        # d_fake_accuracies = np.zeros((epochs, 1))\n",
        "        # d_real_losses = np.zeros((epochs, 1))\n",
        "        # d_real_accuracies = np.zeros((epochs, 1))\n",
        "        g_losses = np.zeros((epochs, 1))\n",
        "        g_accuracies = np.zeros((epochs, 1))\n",
        "        best_epoch = 0\n",
        "\n",
        "        for i, epoch in enumerate(range(epochs)):\n",
        "            # prepare samples\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            c_1 = np.random.random((batch_size, ))\n",
        "            samples_1 = self.generator.predict([noise, c_1])\n",
        "            y_1 =  gs_rf.predict_proba(samples_1)[:,0]  # evaluate Y by running RF classifier\n",
        "\n",
        "            d_loss, d_acc = self.discriminator.train_on_batch([samples_1, c_1, y_1], valid)\n",
        "\n",
        "            c_2 = np.random.random((batch_size, ))\n",
        "            samples_2 = self.generator.predict([noise, c_2])\n",
        "            y_2 =  gs_rf.predict_proba(samples_2)[:,0]  # evaluate Y by running RF classifier\n",
        "\n",
        "            d_loss, d_acc = self.discriminator.train_on_batch([samples_2, y_2, c_2], invalid)\n",
        "\n",
        "            # create training set for the discriminator\n",
        "            # samples, y, c = np.vstack((samples_1, samples_2)), np.vstack((y_1, c_2)), np.vstack((y_2, c_1))\n",
        "            # update discriminator model weights\n",
        "            # d_loss, d_acc = self.discriminator.train_on_batch([samples, y, c], valid_twice)\n",
        "\n",
        "            # # shuffle c and y\n",
        "            # idx = np.random.randint(2, size=batch_size)\n",
        "            # # print(idx)\n",
        "            # for i in range(batch_size):\n",
        "            #   if idx[i] == 0 :\n",
        "            #     tmp = c[i]\n",
        "            #     c[i] = y[i]\n",
        "            #     y[i] = tmp\n",
        "\n",
        "            # d_loss, d_acc = self.discriminator.train_on_batch([samples, c, y], idx)\n",
        "\n",
        "\n",
        "            # np.stack((samples,c,y), axis=-1)\n",
        "\n",
        "            # # create training set for the discriminator\n",
        "            # x, y = np.vstack((x_real, x_fake)), np.vstack((y_real, y_fake))\n",
        "            # # update discriminator model weights\n",
        "            # d_loss, d_acc = self.discriminator.train_on_batch(x, y)\n",
        "\n",
        "            # # evaluate discriminator on real examples\n",
        "            # x_real, y_real = self.generate_real_x_y(X_train, batch_size)\n",
        "            # d_loss_real, d_acc_real = self.discriminator.evaluate(x_real, y_real, verbose=0)\n",
        "            # # evaluate discriminator on fake examples\n",
        "            # x_fake, y_fake = self.generate_fake_x_y(batch_size)\n",
        "            # d_loss_fake, d_acc_fake = self.discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
        "\n",
        "            # d_fake_losses[i] = d_loss_fake\n",
        "            # d_real_losses[i] = d_loss_real\n",
        "            # d_fake_accuracies[i] = d_acc_fake\n",
        "            # d_real_accuracies[i] = d_acc_real\n",
        "\n",
        "            # noise = np.random.normal(0, 1, (batch_size * 2, self.latent_dim)) # Carmel,  WHY TWISE?\n",
        "            # create inverted labels for the fake samples so generator can improve to be 'real'\n",
        "            # update the generator via the discriminator's error\n",
        "            noise = np.random.normal(0, 1, (batch_size*2, self.latent_dim))\n",
        "            c = np.random.normal(0, 1, (batch_size*2, ))\n",
        "            g_loss, g_acc = self.gan.train_on_batch([noise, c], valid_twice)\n",
        "\n",
        "            d_losses[i] = d_loss\n",
        "            d_accuracies[i] = d_acc\n",
        "            g_losses[i] = g_loss\n",
        "            g_accuracies[i] = g_acc\n",
        "            \n",
        "            d_acc_delta_to_0_5 = 1\n",
        "            losses_delta = 1\n",
        "            \n",
        "            if i % 50 == 0:\n",
        "              print(\"epoch %d [D loss: %f, acc.: %.2f%%] [G loss: %f, acc.: %.2f%%]\" % (epoch, d_loss, 100 * d_acc, g_loss, g_acc))\n",
        "              if 500<=i:\n",
        "                if abs(g_loss - d_loss) < losses_delta or abs(g_loss - d_loss) < 0.02: # check that losses converged\n",
        "                  if d_acc_delta_to_0_5 > abs(d_acc - 0.5): # save generator model for closest to 0.5 accuracy \n",
        "                    filename = 'generator_model.h5'\n",
        "                    self.generator.save(filename)\n",
        "                    best_epoch = epoch\n",
        "\n",
        "        print(f'Best epoch: {best_epoch}')\n",
        "            # if epoch % 10 == 0:\n",
        "            #   noise = np.random.normal(0, 1, (1, self.noise_dim))\n",
        "            #   gen_rows = self.generator.predict(noise)\n",
        "            #   print(gen_rows)\n",
        "        return d_losses, d_accuracies, g_losses, g_accuracies"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq2RyaE2VHCg",
        "outputId": "d4ccf172-3cc5-47f4-b06a-342e248873b2"
      },
      "source": [
        "iterations = 2000\n",
        "gan = GAN(30, 61, 'tanh')\n",
        "d_losses, d_accuracies, g_losses, g_accuracies = gan.train(epochs=iterations, batch_size=32)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 31)           0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          4096        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 128)          512         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 128)          0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128)          0           leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          33024       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 256)          0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          131584      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 512)          0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 61)           31293       dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 203,581\n",
            "Trainable params: 201,789\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 61)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 512)          31744       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 512)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 512)          0           leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 256)          131328      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 256)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 256)          0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 128)          32896       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 128)          0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 128)          0           leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            129         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 196,097\n",
            "Trainable params: 196,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 0 [D loss: 0.697642, acc.: 50.00%] [G loss: 0.762694, acc.: 0.33%]\n",
            "epoch 50 [D loss: 0.870917, acc.: 0.00%] [G loss: 0.426867, acc.: 0.98%]\n",
            "epoch 100 [D loss: 0.913229, acc.: 3.12%] [G loss: 0.511894, acc.: 0.92%]\n",
            "epoch 150 [D loss: 0.778949, acc.: 21.88%] [G loss: 0.630800, acc.: 0.66%]\n",
            "epoch 200 [D loss: 0.771024, acc.: 21.88%] [G loss: 0.657066, acc.: 0.66%]\n",
            "epoch 250 [D loss: 0.762134, acc.: 31.25%] [G loss: 0.657482, acc.: 0.69%]\n",
            "epoch 300 [D loss: 0.744668, acc.: 31.25%] [G loss: 0.706155, acc.: 0.47%]\n",
            "epoch 350 [D loss: 0.760226, acc.: 28.12%] [G loss: 0.692329, acc.: 0.55%]\n",
            "epoch 400 [D loss: 0.738787, acc.: 37.50%] [G loss: 0.696147, acc.: 0.58%]\n",
            "epoch 450 [D loss: 0.708140, acc.: 53.12%] [G loss: 0.684829, acc.: 0.55%]\n",
            "epoch 500 [D loss: 0.728876, acc.: 46.88%] [G loss: 0.689652, acc.: 0.53%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 550 [D loss: 0.722821, acc.: 34.38%] [G loss: 0.671935, acc.: 0.66%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 600 [D loss: 0.713169, acc.: 50.00%] [G loss: 0.707457, acc.: 0.39%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 650 [D loss: 0.713770, acc.: 31.25%] [G loss: 0.702652, acc.: 0.48%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 700 [D loss: 0.734080, acc.: 34.38%] [G loss: 0.676595, acc.: 0.62%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 750 [D loss: 0.675097, acc.: 62.50%] [G loss: 0.706967, acc.: 0.50%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 800 [D loss: 0.719454, acc.: 40.62%] [G loss: 0.700247, acc.: 0.42%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 850 [D loss: 0.700954, acc.: 50.00%] [G loss: 0.732733, acc.: 0.39%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 900 [D loss: 0.696463, acc.: 50.00%] [G loss: 0.675529, acc.: 0.53%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 950 [D loss: 0.705840, acc.: 53.12%] [G loss: 0.707106, acc.: 0.52%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1000 [D loss: 0.728650, acc.: 53.12%] [G loss: 0.701485, acc.: 0.47%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1050 [D loss: 0.709825, acc.: 40.62%] [G loss: 0.713483, acc.: 0.42%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1100 [D loss: 0.684375, acc.: 65.62%] [G loss: 0.702218, acc.: 0.47%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1150 [D loss: 0.682756, acc.: 62.50%] [G loss: 0.723831, acc.: 0.45%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1200 [D loss: 0.696992, acc.: 53.12%] [G loss: 0.687522, acc.: 0.61%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1250 [D loss: 0.720324, acc.: 40.62%] [G loss: 0.692761, acc.: 0.56%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1300 [D loss: 0.710753, acc.: 46.88%] [G loss: 0.687778, acc.: 0.62%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1350 [D loss: 0.741269, acc.: 34.38%] [G loss: 0.691405, acc.: 0.55%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1400 [D loss: 0.710687, acc.: 53.12%] [G loss: 0.718003, acc.: 0.44%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1450 [D loss: 0.709091, acc.: 50.00%] [G loss: 0.696931, acc.: 0.48%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1500 [D loss: 0.725244, acc.: 37.50%] [G loss: 0.697916, acc.: 0.53%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1550 [D loss: 0.708659, acc.: 43.75%] [G loss: 0.724312, acc.: 0.44%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1600 [D loss: 0.662581, acc.: 59.38%] [G loss: 0.685597, acc.: 0.56%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1650 [D loss: 0.732797, acc.: 31.25%] [G loss: 0.658629, acc.: 0.59%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1700 [D loss: 0.698996, acc.: 53.12%] [G loss: 0.706106, acc.: 0.50%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1750 [D loss: 0.718662, acc.: 43.75%] [G loss: 0.700549, acc.: 0.47%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1800 [D loss: 0.728514, acc.: 34.38%] [G loss: 0.669134, acc.: 0.58%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1850 [D loss: 0.738381, acc.: 56.25%] [G loss: 0.699137, acc.: 0.45%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1900 [D loss: 0.722572, acc.: 40.62%] [G loss: 0.683214, acc.: 0.55%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "epoch 1950 [D loss: 0.734316, acc.: 40.62%] [G loss: 0.678750, acc.: 0.59%]\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Best epoch: 1950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "ZM9PERydwSj1",
        "outputId": "c5c20899-7aef-4571-fcb0-32ecba9169f1"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "def plot_metric_general(graphs: List[np.ndarray], labels: List[str]) -> None:\n",
        "    import matplotlib.pyplot as plt\n",
        "    epochs = range(1, graphs[0].shape[0] + 1)\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.title('Gan')\n",
        "    for i in range(len(labels)):\n",
        "        plt.plot(epochs, graphs[i])\n",
        "    plt.legend(labels)\n",
        "    plt.show()\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "\n",
        "d_losses_smooth, d_accuracies_smooth, g_losses_smooth, g_accuracies_smooth = moving_average(d_losses.reshape((iterations)), 9), moving_average(d_accuracies.reshape((iterations)), 9), moving_average(g_losses.reshape((iterations)), 9), moving_average(g_accuracies.reshape((iterations)), 9)\n",
        "\n",
        "plot_metric_general([d_losses_smooth, d_accuracies_smooth, g_losses_smooth, g_accuracies_smooth], ['d_losses_smooth', 'd_accuracies_smooth', 'g_losses_smooth', 'g_accuracies_smooth'])\n",
        "# plot_metric_general([d_losses, d_accuracies, g_losses, g_accuracies], ['d_losses', 'd_accuracies', 'g_losses', 'g_accuracies']) \n",
        "# we can see aroud 800 epochs d_fake_accuracies=d_real_accuracies=0.5 and after that it degragates "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waAGk29Rxq3N"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "nisaRy3kz1J8",
        "outputId": "ed2845e6-2eba-4012-cccc-352a0030ff8a"
      },
      "source": [
        "p_proba = gs_rf.predict_proba(df_test)[:,0]\n",
        "sns.displot(p_proba, bins=10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fc880ccf110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JzF-M_k0aOH",
        "outputId": "f5496bf5-f103-4c3c-d0df-ebdb7ab2b9d0"
      },
      "source": [
        "print(f'min {min(p_proba)}, max {max(p_proba)}, avg {sum(p_proba)/len(p_proba)}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min 0.2, max 1.0, avg 0.6984300341296926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcX8i-2g1Ebu",
        "outputId": "36ee6f51-e16d-43ee-f9ff-18630fd22ad8"
      },
      "source": [
        "smaples_len = 1000\n",
        "noise = np.random.normal(0, 1, (smaples_len, 30))\n",
        "c = np.random.uniform(size=(smaples_len, ))\n",
        "loaded_generator = tf.keras.models.load_model('generator_model.h5')\n",
        "# samples = gan.generator.predict([noise, c])\n",
        "samples = loaded_generator.predict([noise, c])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "JAGHmhKu1pwM",
        "outputId": "574d627a-4bf4-4066-e823-7f3af6e7e94f"
      },
      "source": [
        "p_proba_s = gs_rf.predict_proba(samples)[:,0]\n",
        "sns.displot(p_proba_s, bins=10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7fc880c12550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tBQsOEQ3Qkh",
        "outputId": "c9093a61-5ce7-4ea8-ce32-76a6db1c119b"
      },
      "source": [
        "print(f'min {min(p_proba_s)}, max {max(p_proba_s)}, avg {sum(p_proba_s)/len(p_proba_s)}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min 0.33, max 0.59, avg 0.47325999999999985\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}